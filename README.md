# 4th-Sem-Project
Software Engineering

Group Member :-

Ravi Raj (22bds051)

Arnab Rai (22bds005)

Harsh Raj (22bds027)

Preethi Varshala (22bds045)

-----------------------------------------
# Text Summarization Using NLP Techniques

## Overview
This project explores various text summarization techniques using natural language processing (NLP) methods. We implemented three different approaches: Word Frequency, TF-IDF, and BART (Bidirectional and Auto-Regressive Transformers), to generate summaries from input text data.

## Table of Contents
1. [Introduction](#introduction)
2. [Methodology](#methodology)
3. [Experimentation](#experimentation)
4. [Results](#results)
5. [Discussion](#discussion)
6. [Conclusion](#conclusion)
7. [References](#references)

## Introduction
Text summarization is a crucial task in NLP, aiming to condense large volumes of text while preserving essential information. In this project, we investigate three text summarization techniques: Word Frequency, TF-IDF, and BART. Each technique offers a unique approach to summarizing text, ranging from simple statistical methods to advanced deep learning models.

## Methodology
### Word Frequency
- Lowercased the input text for consistency.
- Removed non-alphanumeric characters and tokenized the text into sentences.
- Eliminated stop words and calculated word frequencies.
- Scored sentences based on normalized word frequencies and selected top-ranked sentences for the summary.

### TF-IDF
- Tokenized the text into words and removed stop words.
- Utilized the TF-IDF vectorizer to calculate TF-IDF scores for each word.
- Ranked sentences based on the sum of TF-IDF scores of their constituent words.
- Selected top-ranked sentences to form the summary.

### BART
- Employed the pre-trained BART model and tokenizer for text summarization.
- Tokenized the input text and fed it into the BART model to generate the summary.
- Fine-tuned the BART model on text summarization tasks and decoded the summary from the model output.

## Experimentation
- Used a sample article as input data.
- Preprocessed the dataset by lowercasing the text and removing non-alphanumeric characters.
- Implemented each summarization technique and evaluated their performance based on the quality and coherence of the generated summaries.

## Results
- Presented the summaries generated by Word Frequency, TF-IDF, and BART.
- Compared the effectiveness of each technique in terms of summary quality and coherence.

## Discussion
- Analyzed the findings and discussed the strengths and limitations of each technique.
- Compared the performance of traditional methods (Word Frequency, TF-IDF) with the state-of-the-art BART model.
- Provided insights into scenarios where each technique may be more suitable.

## Conclusion
- Summarized the key findings and implications of the study.
- Highlighted the effectiveness of advanced transformer models like BART in generating high-quality summaries.
- Suggested potential areas for future research and improvements in text summarization using NLP techniques.
